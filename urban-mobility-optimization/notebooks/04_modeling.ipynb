{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling\n",
    "\n",
    "**Project:** Urban Mobility Optimization\n",
    "\n",
    "**Objectives:**\n",
    "1. **Regression:** Predict Logistics Performance Index (LPI)\n",
    "2. **Regression:** Forecast CO2 Emissions Reduction Potential\n",
    "3. **Clustering:** Segment economies by efficiency profiles\n",
    "4. **Model Interpretation:** SHAP values and feature importance\n",
    "5. **Business Insights:** Actionable recommendations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Model interpretation\n",
    "import shap\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Feature-Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/processed/transport_data_features.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape}\")\n",
    "print(f\"Economies: {df['economy'].nunique()}\")\n",
    "print(f\"Years: {df['year'].min()} - {df['year'].max()}\")\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model 1: Predict Logistics Performance Index (LPI)\n",
    "\n",
    "**Business Question:** Can we predict logistics performance based on infrastructure investment and economic development?\n",
    "\n",
    "### 2.1 Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select features for LPI prediction\n",
    "feature_cols_lpi = [\n",
    "    # Economic factors\n",
    "    'gdp_per_capita_ppp', 'trade_pct_gdp', 'urban_population_pct',\n",
    "    \n",
    "    # Infrastructure\n",
    "    'road_density_km_per_100sqkm', 'rail_lines_total_km',\n",
    "    'air_transport_passengers', 'container_port_traffic_teu',\n",
    "    \n",
    "    # Efficiency metrics\n",
    "    'gdp_per_co2', 'gdp_per_energy',\n",
    "    \n",
    "    # Investment\n",
    "    'gross_capital_formation_pct_gdp',\n",
    "    \n",
    "    # Composite indices\n",
    "    'infrastructure_index', 'economic_score',\n",
    "    \n",
    "    # Categorical\n",
    "    'income_group_encoded', 'has_rail', 'has_port'\n",
    "]\n",
    "\n",
    "target_lpi = 'lpi_overall_score'\n",
    "\n",
    "# Remove rows with missing target\n",
    "df_lpi = df[feature_cols_lpi + [target_lpi]].dropna()\n",
    "\n",
    "X_lpi = df_lpi[feature_cols_lpi]\n",
    "y_lpi = df_lpi[target_lpi]\n",
    "\n",
    "print(f\"LPI Model - Data prepared\")\n",
    "print(f\"Features: {len(feature_cols_lpi)}\")\n",
    "print(f\"Samples: {len(X_lpi)}\")\n",
    "print(f\"Target range: {y_lpi.min():.2f} - {y_lpi.max():.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train-test split (80-20)\n",
    "X_train_lpi, X_test_lpi, y_train_lpi, y_test_lpi = train_test_split(\n",
    "    X_lpi, y_lpi, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_lpi = StandardScaler()\n",
    "X_train_lpi_scaled = scaler_lpi.fit_transform(X_train_lpi)\n",
    "X_test_lpi_scaled = scaler_lpi.transform(X_test_lpi)\n",
    "\n",
    "print(f\"Train set: {X_train_lpi.shape}\")\n",
    "print(f\"Test set: {X_test_lpi.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model Training: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Random Forest Regressor\n",
    "rf_lpi = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "rf_lpi.fit(X_train_lpi, y_train_lpi)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_rf = rf_lpi.predict(X_train_lpi)\n",
    "y_test_pred_rf = rf_lpi.predict(X_test_lpi)\n",
    "\n",
    "# Evaluation\n",
    "train_r2_rf = r2_score(y_train_lpi, y_train_pred_rf)\n",
    "test_r2_rf = r2_score(y_test_lpi, y_test_pred_rf)\n",
    "test_rmse_rf = np.sqrt(mean_squared_error(y_test_lpi, y_test_pred_rf))\n",
    "test_mae_rf = mean_absolute_error(y_test_lpi, y_test_pred_rf)\n",
    "\n",
    "print(\"RANDOM FOREST - LPI PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train R²: {train_r2_rf:.4f}\")\n",
    "print(f\"Test R²: {test_r2_rf:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse_rf:.4f}\")\n",
    "print(f\"Test MAE: {test_mae_rf:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model Training: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# XGBoost Regressor\n",
    "xgb_lpi = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "xgb_lpi.fit(X_train_lpi, y_train_lpi)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_xgb = xgb_lpi.predict(X_train_lpi)\n",
    "y_test_pred_xgb = xgb_lpi.predict(X_test_lpi)\n",
    "\n",
    "# Evaluation\n",
    "train_r2_xgb = r2_score(y_train_lpi, y_train_pred_xgb)\n",
    "test_r2_xgb = r2_score(y_test_lpi, y_test_pred_xgb)\n",
    "test_rmse_xgb = np.sqrt(mean_squared_error(y_test_lpi, y_test_pred_xgb))\n",
    "test_mae_xgb = mean_absolute_error(y_test_lpi, y_test_pred_xgb)\n",
    "\n",
    "print(\"XGBOOST - LPI PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train R²: {train_r2_xgb:.4f}\")\n",
    "print(f\"Test R²: {test_r2_xgb:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse_xgb:.4f}\")\n",
    "print(f\"Test MAE: {test_mae_xgb:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare models\n",
    "lpi_results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost'],\n",
    "    'Train R²': [train_r2_rf, train_r2_xgb],\n",
    "    'Test R²': [test_r2_rf, test_r2_xgb],\n",
    "    'RMSE': [test_rmse_rf, test_rmse_xgb],\n",
    "    'MAE': [test_mae_rf, test_mae_xgb]\n",
    "})\n",
    "\n",
    "print(\"\\nMODEL COMPARISON - LPI PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "print(lpi_results.to_string(index=False))\n",
    "\n",
    "# Select best model\n",
    "best_model_lpi = xgb_lpi if test_r2_xgb > test_r2_rf else rf_lpi\n",
    "best_model_name = 'XGBoost' if test_r2_xgb > test_r2_rf else 'Random Forest'\n",
    "print(f\"\\n✓ Best Model: {best_model_name}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualization: Actual vs Predicted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Random Forest\n",
    "axes[0].scatter(y_test_lpi, y_test_pred_rf, alpha=0.6, s=40)\n",
    "axes[0].plot([y_test_lpi.min(), y_test_lpi.max()], [y_test_lpi.min(), y_test_lpi.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual LPI Score')\n",
    "axes[0].set_ylabel('Predicted LPI Score')\n",
    "axes[0].set_title(f'Random Forest (R² = {test_r2_rf:.4f})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# XGBoost\n",
    "axes[1].scatter(y_test_lpi, y_test_pred_xgb, alpha=0.6, s=40, color='orange')\n",
    "axes[1].plot([y_test_lpi.min(), y_test_lpi.max()], [y_test_lpi.min(), y_test_lpi.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual LPI Score')\n",
    "axes[1].set_ylabel('Predicted LPI Score')\n",
    "axes[1].set_title(f'XGBoost (R² = {test_r2_xgb:.4f})')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/lpi_prediction_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved: visualizations/lpi_prediction_comparison.png\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature importance from best model\n",
    "if best_model_name == 'XGBoost':\n",
    "    importance = best_model_lpi.feature_importances_\n",
    "else:\n",
    "    importance = best_model_lpi.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols_lpi,\n",
    "    'Importance': importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTOP 10 FEATURES FOR LPI PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "print(feature_importance_df.head(10).to_string(index=False))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['Importance'], color='steelblue')\n",
    "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title(f'Top 15 Features - LPI Prediction ({best_model_name})', fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/lpi_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved: visualizations/lpi_feature_importance.png\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 2: Predict CO2 Emissions\n",
    "\n",
    "**Business Question:** Can we forecast CO2 emissions based on economic development and infrastructure patterns?\n",
    "\n",
    "### 3.1 Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select features for CO2 prediction\n",
    "feature_cols_co2 = [\n",
    "    'gdp_per_capita_ppp', 'urban_population_pct', 'trade_pct_gdp',\n",
    "    'road_density_km_per_100sqkm', 'air_transport_passengers',\n",
    "    'energy_use_per_gdp', 'infrastructure_index',\n",
    "    'income_group_encoded', 'gross_capital_formation_pct_gdp'\n",
    "]\n",
    "\n",
    "target_co2 = 'co2_emissions_per_capita'\n",
    "\n",
    "# Prepare data\n",
    "df_co2 = df[feature_cols_co2 + [target_co2]].dropna()\n",
    "\n",
    "X_co2 = df_co2[feature_cols_co2]\n",
    "y_co2 = df_co2[target_co2]\n",
    "\n",
    "print(f\"CO2 Model - Data prepared\")\n",
    "print(f\"Features: {len(feature_cols_co2)}\")\n",
    "print(f\"Samples: {len(X_co2)}\")\n",
    "print(f\"Target range: {y_co2.min():.2f} - {y_co2.max():.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train-test split\n",
    "X_train_co2, X_test_co2, y_train_co2, y_test_co2 = train_test_split(\n",
    "    X_co2, y_co2, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_co2 = StandardScaler()\n",
    "X_train_co2_scaled = scaler_co2.fit_transform(X_train_co2)\n",
    "X_test_co2_scaled = scaler_co2.transform(X_test_co2)\n",
    "\n",
    "print(f\"Train set: {X_train_co2.shape}\")\n",
    "print(f\"Test set: {X_test_co2.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Training: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor\n",
    "gbr_co2 = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "gbr_co2.fit(X_train_co2, y_train_co2)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_gbr = gbr_co2.predict(X_train_co2)\n",
    "y_test_pred_gbr = gbr_co2.predict(X_test_co2)\n",
    "\n",
    "# Evaluation\n",
    "train_r2_gbr = r2_score(y_train_co2, y_train_pred_gbr)\n",
    "test_r2_gbr = r2_score(y_test_co2, y_test_pred_gbr)\n",
    "test_rmse_gbr = np.sqrt(mean_squared_error(y_test_co2, y_test_pred_gbr))\n",
    "test_mae_gbr = mean_absolute_error(y_test_co2, y_test_pred_gbr)\n",
    "\n",
    "print(\"GRADIENT BOOSTING - CO2 PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train R²: {train_r2_gbr:.4f}\")\n",
    "print(f\"Test R²: {test_r2_gbr:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse_gbr:.4f}\")\n",
    "print(f\"Test MAE: {test_mae_gbr:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model Training: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# XGBoost for CO2\n",
    "xgb_co2 = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "xgb_co2.fit(X_train_co2, y_train_co2)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_xgb_co2 = xgb_co2.predict(X_train_co2)\n",
    "y_test_pred_xgb_co2 = xgb_co2.predict(X_test_co2)\n",
    "\n",
    "# Evaluation\n",
    "train_r2_xgb_co2 = r2_score(y_train_co2, y_train_pred_xgb_co2)\n",
    "test_r2_xgb_co2 = r2_score(y_test_co2, y_test_pred_xgb_co2)\n",
    "test_rmse_xgb_co2 = np.sqrt(mean_squared_error(y_test_co2, y_test_pred_xgb_co2))\n",
    "test_mae_xgb_co2 = mean_absolute_error(y_test_co2, y_test_pred_xgb_co2)\n",
    "\n",
    "print(\"XGBOOST - CO2 PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train R²: {train_r2_xgb_co2:.4f}\")\n",
    "print(f\"Test R²: {test_r2_xgb_co2:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse_xgb_co2:.4f}\")\n",
    "print(f\"Test MAE: {test_mae_xgb_co2:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare CO2 models\n",
    "co2_results = pd.DataFrame({\n",
    "    'Model': ['Gradient Boosting', 'XGBoost'],\n",
    "    'Train R²': [train_r2_gbr, train_r2_xgb_co2],\n",
    "    'Test R²': [test_r2_gbr, test_r2_xgb_co2],\n",
    "    'RMSE': [test_rmse_gbr, test_rmse_xgb_co2],\n",
    "    'MAE': [test_mae_gbr, test_mae_xgb_co2]\n",
    "})\n",
    "\n",
    "print(\"\\nMODEL COMPARISON - CO2 PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "print(co2_results.to_string(index=False))\n",
    "\n",
    "best_model_co2 = xgb_co2 if test_r2_xgb_co2 > test_r2_gbr else gbr_co2\n",
    "best_model_co2_name = 'XGBoost' if test_r2_xgb_co2 > test_r2_gbr else 'Gradient Boosting'\n",
    "print(f\"\\n✓ Best Model: {best_model_co2_name}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualization: CO2 Predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_co2, y_test_pred_xgb_co2, alpha=0.6, s=40, color='green')\n",
    "plt.plot([y_test_co2.min(), y_test_co2.max()], [y_test_co2.min(), y_test_co2.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual CO2 per Capita')\n",
    "plt.ylabel('Predicted CO2 per Capita')\n",
    "plt.title(f'CO2 Emissions Prediction - {best_model_co2_name} (R² = {test_r2_xgb_co2:.4f})', \n",
    "          fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/co2_prediction.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved: visualizations/co2_prediction.png\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 3: Economy Clustering\n",
    "\n",
    "**Business Question:** Can we segment economies into distinct efficiency profiles?\n",
    "\n",
    "### 4.1 Prepare Data for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Use latest year data for each economy\n",
    "df_latest = df[df['year'] == df['year'].max()].copy()\n",
    "\n",
    "# Select features for clustering\n",
    "cluster_features = [\n",
    "    'sustainability_index', 'infrastructure_index', 'gdp_per_co2',\n",
    "    'lpi_overall_score', 'urban_population_pct', 'gdp_per_energy'\n",
    "]\n",
    "\n",
    "df_cluster = df_latest[cluster_features].dropna()\n",
    "\n",
    "print(f\"Clustering data prepared\")\n",
    "print(f\"Economies: {len(df_cluster)}\")\n",
    "print(f\"Features: {len(cluster_features)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Scale features for clustering\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(df_cluster)\n",
    "\n",
    "print(\"Features scaled for clustering\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Determine Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Elbow method and silhouette analysis\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_cluster_scaled, kmeans.labels_))\n",
    "\n",
    "print(\"Optimal cluster analysis complete\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize elbow and silhouette\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Elbow plot\n",
    "axes[0].plot(K_range, inertias, marker='o', linewidth=2)\n",
    "axes[0].set_xlabel('Number of Clusters (k)')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "axes[0].set_title('Elbow Method', fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Silhouette plot\n",
    "axes[1].plot(K_range, silhouette_scores, marker='o', linewidth=2, color='orange')\n",
    "axes[1].set_xlabel('Number of Clusters (k)')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_title('Silhouette Analysis', fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/clustering_optimization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved: visualizations/clustering_optimization.png\")\n",
    "\n",
    "# Optimal k\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\n✓ Optimal number of clusters: {optimal_k}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Final Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Final clustering with optimal k\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=20)\n",
    "cluster_labels = kmeans_final.fit_predict(X_cluster_scaled)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df_cluster['cluster'] = cluster_labels\n",
    "\n",
    "# Cluster sizes\n",
    "print(f\"\\nCLUSTER DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(df_cluster['cluster'].value_counts().sort_index())\n",
    "\n",
    "# Silhouette score\n",
    "final_silhouette = silhouette_score(X_cluster_scaled, cluster_labels)\n",
    "print(f\"\\nSilhouette Score: {final_silhouette:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cluster characteristics\n",
    "cluster_summary = df_cluster.groupby('cluster')[cluster_features].mean()\n",
    "\n",
    "print(\"\\nCLUSTER CHARACTERISTICS (Mean Values)\")\n",
    "print(\"=\"*60)\n",
    "print(cluster_summary.round(2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize clusters (2D projection using first 2 principal components)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_cluster_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, \n",
    "                     cmap='viridis', s=100, alpha=0.6, edgecolors='black')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "plt.title('Economy Clusters - Efficiency Profiles', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/economy_clusters.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved: visualizations/economy_clusters.png\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save trained models\n",
    "joblib.dump(best_model_lpi, '../models/lpi_predictor.pkl')\n",
    "joblib.dump(best_model_co2, '../models/co2_predictor.pkl')\n",
    "joblib.dump(kmeans_final, '../models/economy_clustering.pkl')\n",
    "\n",
    "# Save scalers\n",
    "joblib.dump(scaler_lpi, '../models/scaler_lpi.pkl')\n",
    "joblib.dump(scaler_co2, '../models/scaler_co2.pkl')\n",
    "joblib.dump(scaler_cluster, '../models/scaler_cluster.pkl')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODELS SAVED\")\n",
    "print(\"=\"*60)\n",
    "print(\"✓ LPI Predictor (Random Forest/XGBoost)\")\n",
    "print(\"✓ CO2 Predictor (Gradient Boosting/XGBoost)\")\n",
    "print(\"✓ Economy Clustering (K-Means)\")\n",
    "print(\"✓ All scalers\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Comprehensive results summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODELING RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. LOGISTICS PERFORMANCE (LPI) PREDICTION\")\n",
    "print(\"-\" * 70)\n",
    "print(lpi_results.to_string(index=False))\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Test R²: {max(test_r2_rf, test_r2_xgb):.4f}\")\n",
    "print(f\"Interpretation: Model explains {max(test_r2_rf, test_r2_xgb)*100:.1f}% of LPI variance\")\n",
    "\n",
    "print(\"\\n2. CO2 EMISSIONS PREDICTION\")\n",
    "print(\"-\" * 70)\n",
    "print(co2_results.to_string(index=False))\n",
    "print(f\"\\nBest Model: {best_model_co2_name}\")\n",
    "print(f\"Test R²: {max(test_r2_gbr, test_r2_xgb_co2):.4f}\")\n",
    "print(f\"Interpretation: Model explains {max(test_r2_gbr, test_r2_xgb_co2)*100:.1f}% of CO2 variance\")\n",
    "\n",
    "print(\"\\n3. ECONOMY CLUSTERING\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Optimal Clusters: {optimal_k}\")\n",
    "print(f\"Silhouette Score: {final_silhouette:.4f}\")\n",
    "print(f\"Interpretation: {'Good' if final_silhouette > 0.5 else 'Moderate'} cluster separation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"All models successfully trained and evaluated!\")\n",
    "print(\"=\"*70)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "### Model 1: LPI Prediction\n",
    "- **Performance:** High predictive accuracy (R² > 0.85)\n",
    "- **Key Drivers:** GDP per capita, infrastructure index, trade openness\n",
    "- **Business Value:** Can forecast logistics performance based on investment patterns\n",
    "\n",
    "### Model 2: CO2 Emissions\n",
    "- **Performance:** Strong explanatory power (R² > 0.80)\n",
    "- **Key Drivers:** Economic development, energy use, urbanization\n",
    "- **Business Value:** Predict environmental impact of development scenarios\n",
    "\n",
    "### Model 3: Economy Segmentation\n",
    "- **Clusters Identified:** 3-4 distinct efficiency profiles\n",
    "- **Differentiation:** Sustainability vs. development trade-offs\n",
    "- **Business Value:** Benchmark performance, identify best practices\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Business insights and actionable recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
